import sqlite3
from datetime import datetime, timezone
import logging
import numpy as np
from typing import List, Dict, Set
import re

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext, CallbackQueryHandler

from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode
from telethon import TelegramClient, events
from telethon.tl.types import Message as TelethonMessage

from sentence_transformers import SentenceTransformer


class Config:
    # –¢–æ–∫–µ–Ω –≤–∞—à–µ–≥–æ Telegram-–±–æ—Ç–∞ (–ø–æ–ª—É—á–∏—Ç—å —É @BotFather)
    BOT_TOKEN = "1234567890abcdef"

    # API ID –∏ API Hash –≤–∞—à–µ–≥–æ Telegram-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–ø–æ–ª—É—á–∏—Ç—å –Ω–∞ my.telegram.org)
    API_ID = 123456789
    API_HASH = "123abc"

    # –ò–º—è —Ñ–∞–π–ª–∞ —Å–µ—Å—Å–∏–∏ –¥–ª—è Telethon
    SESSION_NAME = "new_session"

    # –ü—É–±–ª–∏—á–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    CHANNELS_TO_INDEX = ["channel_1", "channel_N"]

    # –ù–∞–∑–≤–∞–Ω–∏–µ –ë–î
    DATABASE_NAME = "search_data.db"

    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä
    MODEL_NAME = "all-MiniLM-L6-v2"

    # –°—Ö–æ–∂–µ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
    SIMILARITY_THRESHOLD = 0.35

    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    MAX_MESSAGE_LENGTH = 4000


logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

try:
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SentenceTransformer: {Config.MODEL_NAME}...")
    similarity_model = SentenceTransformer(Config.MODEL_NAME)
    logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ SentenceTransformer: {e}")
    logger.error("–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –ø–æ–∏—Å–∫–∞ –ø–æ —Å–º—ã—Å–ª—É –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
    similarity_model = None


class Database:
    def __init__(self, db_name: str):
        self.db_name = db_name
        self.conn = sqlite3.connect(db_name, check_same_thread=False)
        self._create_tables()

    def _create_tables(self):
        cursor = self.conn.cursor()
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            channel_username TEXT NOT NULL,
            telegram_message_id INTEGER NOT NULL,
            text TEXT NOT NULL,
            message_date TIMESTAMP NOT NULL,
            embedding BLOB,
            added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(channel_username, telegram_message_id)
        )
        ''')
        self.conn.commit()

    def save_message(self, channel_username: str, msg_id: int, text: str, date: datetime,
                     embedding: np.ndarray = None) -> int | None:
        try:
            cursor = self.conn.cursor()
            embedding_blob = embedding.tobytes() if embedding is not None and similarity_model else None
            cursor.execute(
                "INSERT OR IGNORE INTO messages (channel_username, telegram_message_id, text, message_date, embedding) VALUES (?, ?, ?, ?, ?)",
                (channel_username.lower(), msg_id, text, date, embedding_blob)
            )
            self.conn.commit()
            return cursor.lastrowid if cursor.rowcount > 0 else None
        except sqlite3.Error as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ {channel_username} –≤ –ë–î: {e}")
            return None

    def search_messages(self, query_text: str, query_terms: List[str], search_mode: str,  # –í–º–µ—Å—Ç–æ is_phrase_search
                        similarity_query_embedding: np.ndarray = None, limit: int = 5) -> List[Dict]:
        results = []
        seen_message_ids = set()
        cursor = self.conn.cursor()

        if search_mode == "phrase" and query_text:
            sql_text_conditions = "lower(text) LIKE ?"
            text_params = ['%' + query_text.lower() + '%']
            logger.debug(f"Phrase search: condition='{sql_text_conditions}', params='{text_params}'")

            sql_query = f"""
                SELECT id, channel_username, telegram_message_id, text, message_date, embedding
                FROM messages WHERE {sql_text_conditions} ORDER BY message_date DESC LIMIT {limit}"""
            try:
                cursor.execute(sql_query, text_params)
                for row in cursor.fetchall():
                    if row[
                        0] not in seen_message_ids:
                        try:
                            msg_date_obj = datetime.fromisoformat(row[4]) if isinstance(row[4], str) else row[4]
                            results.append({
                                "db_id": row[0], "channel_username": row[1], "telegram_message_id": row[2],
                                "text": row[3], "message_date": msg_date_obj, "score": 1.0, "match_type": "phrase"
                            })
                            seen_message_ids.add(row[0])
                        except ValueError as ve:
                            logger.error(
                                f"DB Error (phrase search date conversion) for msg_id {row[0]}: {ve}, value: {row[4]}")
            except sqlite3.Error as e:
                logger.error(f"DB Error (phrase search): {e}")

        elif search_mode == "words" and query_terms:
            sql_text_conditions = " AND ".join([f"lower(text) LIKE ?" for _ in query_terms])
            text_params = ['%' + term + '%' for term in query_terms]
            logger.debug(f"All words search: condition='{sql_text_conditions}', params='{text_params}'")

            sql_query = f"""
                SELECT id, channel_username, telegram_message_id, text, message_date, embedding
                FROM messages WHERE {sql_text_conditions} ORDER BY message_date DESC LIMIT {limit}"""
            try:
                cursor.execute(sql_query, text_params)
                for row in cursor.fetchall():
                    if row[0] not in seen_message_ids:
                        try:
                            msg_date_obj = datetime.fromisoformat(row[4]) if isinstance(row[4], str) else row[4]
                            results.append({
                                "db_id": row[0], "channel_username": row[1], "telegram_message_id": row[2],
                                "text": row[3], "message_date": msg_date_obj, "score": 1.0, "match_type": "words"
                            })
                            seen_message_ids.add(row[0])
                        except ValueError as ve:
                            logger.error(
                                f"DB Error (words search date conversion) for msg_id {row[0]}: {ve}, value: {row[4]}")
            except sqlite3.Error as e:
                logger.error(f"DB Error (words search): {e}")

        needs_semantic_search = False
        if search_mode == "semantic":
            if not similarity_model or similarity_query_embedding is None:
                logger.warning("Semantic search requested, but model or query embedding is not available.")
            else:
                needs_semantic_search = True
        elif len(results) < limit and similarity_model and similarity_query_embedding is not None:
            needs_semantic_search = True

        if needs_semantic_search:
            logger.debug(f"Performing semantic search (mode: {search_mode}, current results: {len(results)}).")
            try:
                cursor.execute(
                    "SELECT id, channel_username, telegram_message_id, text, message_date, embedding FROM messages WHERE embedding IS NOT NULL"
                )
                potential_semantic_matches = []
                all_db_messages_for_semantic = cursor.fetchall()

                for row in all_db_messages_for_semantic:
                    if row[0] in seen_message_ids and search_mode != "semantic":
                        continue

                    msg_embedding_db = np.frombuffer(row[5], dtype=np.float32)
                    if np.linalg.norm(msg_embedding_db) == 0 or np.linalg.norm(similarity_query_embedding) == 0:
                        similarity_score = 0.0
                    else:
                        similarity_score = np.dot(similarity_query_embedding, msg_embedding_db) / (
                                np.linalg.norm(similarity_query_embedding) * np.linalg.norm(msg_embedding_db))
                    logger.info(f"Semantic check - Msg DB ID: {row[0]}, Score: {similarity_score:.4f}")

                    if similarity_score >= Config.SIMILARITY_THRESHOLD:
                        try:
                            msg_date_obj = datetime.fromisoformat(row[4]) if isinstance(row[4], str) else row[4]
                            is_new_match = True
                            if search_mode != "semantic":
                                for res_item in results:
                                    if res_item["db_id"] == row[0]:
                                        is_new_match = False
                                        break

                            if is_new_match:
                                potential_semantic_matches.append({
                                    "db_id": row[0], "channel_username": row[1], "telegram_message_id": row[2],
                                    "text": row[3], "message_date": msg_date_obj, "score": float(similarity_score),
                                    "match_type": "semantic"
                                })
                        except ValueError as ve:
                            logger.error(
                                f"DB Error (semantic date conversion) for msg_id {row[0]}: {ve}, value: {row[4]}")

                potential_semantic_matches.sort(key=lambda x: x["score"], reverse=True)

                if search_mode == "semantic":
                    results = potential_semantic_matches
                else:
                    for match in potential_semantic_matches:
                        if len(results) >= limit:
                            break
                        if match["db_id"] not in seen_message_ids:
                            results.append(match)
                            seen_message_ids.add(match["db_id"])
            except sqlite3.Error as e:
                logger.error(f"DB Error (semantic messages): {e}")

        def sort_key(item):
            match_type_priority = 0
            if item.get("match_type") == "phrase":
                match_type_priority = 2
            elif item.get("match_type") == "words":
                match_type_priority = 1

            score = item.get("score", 0.0)
            freshness = item["message_date"].timestamp() if item["message_date"] else 0
            return (match_type_priority, score, freshness)

        results.sort(key=sort_key, reverse=True)
        return results[:limit]

    def close(self):
        if self.conn:
            self.conn.close()
            logger.info("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ.")

class NewsAggregatorBot:
    def __init__(self):
        self.db = Database(Config.DATABASE_NAME)
        self.ptb_application = Application.builder().token(Config.BOT_TOKEN).build()
        self.telethon_client = TelegramClient(Config.SESSION_NAME, Config.API_ID, Config.API_HASH)
        self.user_search_mode: Dict[int, str] = {}
        self.ptb_application.post_init = self.post_ptb_init
        self.ptb_application.post_shutdown = self.post_ptb_shutdown

        self._setup_ptb_handlers()
        self.channels_to_index_set: Set[str] = {ch.lower().replace("@", "") for ch in Config.CHANNELS_TO_INDEX}

    async def _parse_channel_history(self, channel_username: str, limit: int):
        if limit == 0:
            return
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è @{channel_username}, –ª–∏–º–∏—Ç: {limit} —Å–æ–æ–±—â–µ–Ω–∏–π...")
        count = 0
        try:
            async for message in self.telethon_client.iter_messages(channel_username, limit=limit):
                if message.text:
                    cursor = self.db.conn.cursor()
                    cursor.execute("SELECT 1 FROM messages WHERE channel_username = ? AND telegram_message_id = ?",
                                   (channel_username.lower(), message.id))
                    if cursor.fetchone():
                        logger.debug(f"–°–æ–æ–±—â–µ–Ω–∏–µ {message.id} –∏–∑ @{channel_username} —É–∂–µ –≤ –ë–î (–∏—Å—Ç–æ—Ä–∏—è).")
                        continue
                    msg_embedding = similarity_model.encode(message.text) if similarity_model else None
                    msg_date_utc = message.date.replace(tzinfo=timezone.utc) if message.date.tzinfo is None \
                        else message.date.astimezone(timezone.utc)

                    saved_id = self.db.save_message(
                        channel_username.lower(),
                        message.id,
                        message.text,
                        msg_date_utc,
                        msg_embedding
                    )
                    if saved_id:
                        count += 1
            logger.info(f"–ó–∞–≤–µ—Ä—à—ë–Ω –ø–∞—Ä—Å–∏–Ω–≥ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è @{channel_username}. –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö: {count}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∏—Å—Ç–æ—Ä–∏–∏ @{channel_username}: {e}", exc_info=True)

    async def post_ptb_init(self, application: Application):
        logger.info("PTB –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ó–∞–ø—É—Å–∫ Telethon –∫–ª–∏–µ–Ω—Ç–∞...")
        try:
            logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ Telethon –∫–ª–∏–µ–Ω—Ç–∞ —Å —Ç–æ–∫–µ–Ω–æ–º –±–æ—Ç–∞...")
            await self.telethon_client.start(bot_token=Config.BOT_TOKEN)
            me = await self.telethon_client.get_me()
            logger.info(f"Telethon –∫–ª–∏–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω –∫–∞–∫ –±–æ—Ç: {me.username if me.username else me.first_name}")

            logger.info(
                f"Telethon –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–∞–Ω–∞–ª–æ–≤, —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –≤ CHANNELS_TO_INDEX: {self.channels_to_index_set}")
            if not self.channels_to_index_set:
                logger.warning("–°–ø–∏—Å–æ–∫ CHANNELS_TO_INDEX –ø—É—Å—Ç! –ë–æ—Ç –Ω–µ –±—É–¥–µ—Ç —Å–æ–±–∏—Ä–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è.")

            self._setup_telethon_handlers()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Telethon –∫–ª–∏–µ–Ω—Ç–∞: {e}", exc_info=True)
            raise RuntimeError(f"Telethon –∫–ª–∏–µ–Ω—Ç –Ω–µ —Å–º–æ–≥ –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è: {e}")

    async def post_ptb_shutdown(self, application: Application):
        logger.info("PTB –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É...")
        if self.telethon_client.is_connected():
            logger.info("–û—Ç–∫–ª—é—á–µ–Ω–∏–µ Telethon –∫–ª–∏–µ–Ω—Ç–∞...")
            await self.telethon_client.disconnect()
            logger.info("Telethon –∫–ª–∏–µ–Ω—Ç –æ—Ç–∫–ª—é—á–µ–Ω.")
        self.db.close()

    def _setup_ptb_handlers(self):
        self.ptb_application.add_handler(CommandHandler("start", self.start_command))
        self.ptb_application.add_handler(
            CommandHandler("home", self.start_command))  # –ö–Ω–æ–ø–∫–∞ "–í –Ω–∞—á–∞–ª–æ" –±—É–¥–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å /start
        self.ptb_application.add_handler(CommandHandler("indexedchannels", self.indexed_channels_command))
        self.ptb_application.add_handler(CommandHandler("searchmode", self.search_mode_command))
        self.ptb_application.add_handler(
            CallbackQueryHandler(self.button_callback_handler))  # –û–¥–∏–Ω –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –≤—Å–µ—Ö –∫–Ω–æ–ø–æ–∫
        self.ptb_application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_search_query))

    def _setup_telethon_handlers(self):
        @self.telethon_client.on(events.NewMessage())
        async def handle_new_channel_message(event: events.NewMessage.Event):
            message: TelethonMessage = event.message
            channel_username = None
            if hasattr(message.chat, 'username') and message.chat.username:
                channel_username = message.chat.username.lower()
            if not channel_username or channel_username not in self.channels_to_index_set:
                return
            if message.text:
                logger.info(f"Telethon: –ù–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ @{channel_username} (–∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º—ã–π): {message.text[:50]}...")
                msg_embedding = similarity_model.encode(message.text) if similarity_model else None
                msg_date_utc = message.date.replace(
                    tzinfo=timezone.utc) if message.date.tzinfo is None else message.date.astimezone(timezone.utc)

                self.db.save_message(
                    channel_username,
                    message.id,
                    message.text,
                    msg_date_utc,
                    msg_embedding
                )
    async def start_command(self, update: Update, context: CallbackContext, message_id_to_edit: int = None):
        user = update.effective_user
        if user:
            self.user_search_mode[user.id] = "words"

        text = (
            rf"–ü—Ä–∏–≤–µ—Ç, {user.mention_html() if user else ''}! –Ø –±–æ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º."
            "\n\n–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—ã:"
            "\n/indexedchannels - —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞."
            "\n/searchmode - –∏–∑–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞."
            f"\n\n–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: <b>{self._get_current_mode_display(user.id if user else None)}</b>."
            "\n–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞."
        )
        keyboard = [
            [
                InlineKeyboardButton("–ü–æ —Å–ª–æ–≤–∞–º", callback_data="setmode_words"),
                InlineKeyboardButton("–§—Ä–∞–∑–∞", callback_data="setmode_phrase"),
                InlineKeyboardButton("–ü–æ —Å–º—ã—Å–ª—É", callback_data="setmode_semantic")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        if message_id_to_edit and update.callback_query:
            try:
                await context.bot.edit_message_text(
                    chat_id=update.callback_query.message.chat_id,
                    message_id=message_id_to_edit,
                    text=text,
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.HTML
                )
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è start_command: {e}")
                await context.bot.send_message(update.callback_query.message.chat_id, text, reply_markup=reply_markup,
                                               parse_mode=ParseMode.HTML)

        elif update.message:
            await update.message.reply_html(text, reply_markup=reply_markup)

    def _get_current_mode_display(self, user_id: int | None) -> str:
        if user_id is None: return "–ø–æ —Å–ª–æ–≤–∞–º (–ø–æ —É–º–æ–ª—á.)"
        mode = self.user_search_mode.get(user_id, "words")
        if mode == "words": return "–ø–æ —Å–ª–æ–≤–∞–º"
        if mode == "phrase": return "—Ç–æ—á–Ω–∞—è —Ñ—Ä–∞–∑–∞"
        if mode == "semantic": return "–ø–æ —Å–º—ã—Å–ª—É"
        return "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def search_mode_command(self, update: Update, context: CallbackContext):
        keyboard = [
            [
                InlineKeyboardButton("–ü–æ —Å–ª–æ–≤–∞–º", callback_data="setmode_words"),
                InlineKeyboardButton("–§—Ä–∞–∑–∞", callback_data="setmode_phrase"),
                InlineKeyboardButton("–ü–æ —Å–º—ã—Å–ª—É", callback_data="setmode_semantic")
            ],
            [InlineKeyboardButton("üè† –í –Ω–∞—á–∞–ª–æ", callback_data="gohome")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        current_mode_display = self._get_current_mode_display(update.effective_user.id)
        await update.message.reply_text(f"–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞. –¢–µ–∫—É—â–∏–π: {current_mode_display}",
                                        reply_markup=reply_markup)

    async def button_callback_handler(self, update: Update, context: CallbackContext):
        query = update.callback_query
        await query.answer()
        user_id = query.from_user.id

        action = query.data.split('_')[0]

        if query.data == "gohome":
            await self.start_command(update, context, message_id_to_edit=query.message.message_id)
            return

        if action == "setmode":
            mode = query.data.split('_')[1]
            self.user_search_mode[user_id] = mode
            mode_display = self._get_current_mode_display(user_id)
            try:
                keyboard = [
                    [
                        InlineKeyboardButton("–ü–æ —Å–ª–æ–≤–∞–º" + (" ‚úÖ" if mode == "words" else ""),
                                             callback_data="setmode_words"),
                        InlineKeyboardButton("–§—Ä–∞–∑–∞" + (" ‚úÖ" if mode == "phrase" else ""),
                                             callback_data="setmode_phrase"),
                        InlineKeyboardButton("–ü–æ —Å–º—ã—Å–ª—É" + (" ‚úÖ" if mode == "semantic" else ""),
                                             callback_data="setmode_semantic")
                    ],
                    [InlineKeyboardButton("üè† –í –Ω–∞—á–∞–ª–æ", callback_data="gohome")]
                ]
                reply_markup = InlineKeyboardMarkup(keyboard)
                await query.edit_message_text(
                    text=f"–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: <b>{mode_display}</b>.\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å.",
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.HTML
                )
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è setmode: {e}")
                await context.bot.send_message(chat_id=user_id,
                                               text=f"–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {mode_display}.\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å.")
        else:
            logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π callback_data: {query.data}")

    async def indexed_channels_command(self, update: Update, context: CallbackContext):
        if not self.channels_to_index_set:
            await update.message.reply_text("–°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –Ω–µ –∑–∞–¥–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.")
            return
        response_lines = ["–Ø –∏—â—É –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫–∞–Ω–∞–ª–∞–º (–µ—Å–ª–∏ —è –≤ –Ω–∏—Ö —Å–æ—Å—Ç–æ—é):"]
        sorted_channels = sorted(list(self.channels_to_index_set))
        for ch_username in sorted_channels:
            response_lines.append(f"- @{ch_username}")
        response_text = "\n".join(response_lines)
        await update.message.reply_text(response_text)

    async def handle_search_query(self, update: Update, context: CallbackContext):
        if not update.message or not update.message.text:
            logger.info("–ü–æ–ª—É—á–µ–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞—é.")
            return

        query_text_full = update.message.text.strip()
        user_id = update.effective_user.id

        if not query_text_full:
            await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –Ω–µ–ø—É—Å—Ç–æ–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.")
            return

        search_mode = self.user_search_mode.get(user_id, "words")
        mode_display = self._get_current_mode_display(user_id)

        await update.message.reply_text(f"–ò—â—É \"{query_text_full}\" (—Ä–µ–∂–∏–º: {mode_display})...")

        query_terms = []
        if search_mode == "words":
            query_terms = [term.lower() for term in re.findall(r'\b\w+\b', query_text_full)]
            if not query_terms:
                await update.message.reply_text("–í —Ä–µ–∂–∏–º–µ '–ø–æ —Å–ª–æ–≤–∞–º' –≤–∞—à –∑–∞–ø—Ä–æ—Å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞.")
                return

        logger.info(
            f"Search query: '{query_text_full}', mode: {search_mode}, parsed terms: {query_terms if query_terms else 'N/A'}")

        query_embedding = None
        if similarity_model and (
                search_mode == "semantic" or search_mode == "words"):
            query_embedding = similarity_model.encode(query_text_full)

        found_messages = self.db.search_messages(
            query_text=query_text_full,
            query_terms=query_terms,
            search_mode=search_mode,
            similarity_query_embedding=query_embedding,
            limit=5
        )

        home_button_keyboard = InlineKeyboardMarkup([[InlineKeyboardButton("üè† –í –Ω–∞—á–∞–ª–æ", callback_data="gohome")]])

        if not found_messages:
            await update.message.reply_text("–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.",
                                            reply_markup=home_button_keyboard)
            return

        response_parts = []
        for i, msg_data in enumerate(found_messages):
            link = f"https://t.me/{msg_data['channel_username']}/{msg_data['telegram_message_id']}"
            text_preview = msg_data['text']
            match_type_display = msg_data.get("match_type", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")

            if search_mode == "phrase" and match_type_display == "phrase" and query_text_full.lower() in text_preview.lower():
                start_index = text_preview.lower().find(query_text_full.lower())
                end_index = start_index + len(query_text_full)
                context_before = max(0, start_index - 50)
                context_after = min(len(text_preview), end_index + 50)
                highlighted_text = (text_preview[context_before:start_index].replace("<", "<").replace(">", ">") +
                                    f"<b>{text_preview[start_index:end_index].replace('<', '<').replace('>', '>')}</b>" +
                                    text_preview[end_index:context_after].replace("<", "<").replace(">", ">"))
                text_preview = ("..." if context_before > 0 else "") + highlighted_text + \
                               ("..." if context_after < len(text_preview) else "")
            else:
                text_preview = msg_data['text'][:200].replace("<", "<").replace(">", ">") + \
                               ("..." if len(msg_data['text']) > 200 else "")

            score_info = ""
            if msg_data['score'] == 1.0:
                score_info = f"(—Ç–∏–ø: {match_type_display})"
            elif "score" in msg_data:
                score_info = f"(—Å—Ö–æ–∂–µ—Å—Ç—å: {msg_data['score']:.2f}, —Ç–∏–ø: {match_type_display})"
            date_str = msg_data['message_date'].strftime('%Y-%m-%d %H:%M') if msg_data['message_date'] else "N/A"
            response_parts.append(
                f"<b>–†–µ–∑—É–ª—å—Ç–∞—Ç {i + 1}</b> {score_info}\n"
                f"üì£ –ö–∞–Ω–∞–ª: @{msg_data['channel_username']}\n"
                f"üìù {text_preview}\n"
                f"üîó <a href='{link}'>–ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–æ–æ–±—â–µ–Ω–∏—é</a>\n"
                f"üóìÔ∏è {date_str}"
            )
        full_response = "\n\n---\n\n".join(response_parts)
        try:
            if len(full_response) <= Config.MAX_MESSAGE_LENGTH:
                await update.message.reply_html(full_response, disable_web_page_preview=True,
                                                reply_markup=home_button_keyboard)
            else:
                await update.message.reply_text(
                    "–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π. –û—Ç–ø—Ä–∞–≤–ª—è—é –ø–æ —á–∞—Å—Ç—è–º (—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–ø—Ä–æ—â–µ–Ω–æ):",
                    reply_markup=home_button_keyboard
                )
                for part_html in response_parts:
                    try:
                        await update.message.reply_html(part_html, disable_web_page_preview=True,
                                                        reply_markup=home_button_keyboard)
                    except Exception as e_part:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —á–∞—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e_part}")
                        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —á–∞—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.",
                                                        reply_markup=home_button_keyboard)
                        break
        except Exception as e_send:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞: {e_send}")
            await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.",
                                            reply_markup=home_button_keyboard)

    def run(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞ (–±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤)."""
        logger.info("–ó–∞–ø—É—Å–∫ PTB –ø–æ–ª–ª–∏–Ω–≥–∞...")
        self.ptb_application.run_polling()
        logger.info("PTB –ø–æ–ª–ª–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

if __name__ == '__main__':
    if not Config.BOT_TOKEN or \
            not Config.API_ID or \
            not Config.API_HASH:
        logger.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è BOT_TOKEN, API_ID –∏ API_HASH –≤ –∫–ª–∞—Å—Å–µ Config.")
    else:
        bot = NewsAggregatorBot()
        try:
            bot.run()
        except KeyboardInterrupt:
            logger.info("–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞ (Ctrl+C).")
        except Exception as e:
            logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}", exc_info=True)
        finally:
            logger.info("–ë–æ—Ç –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É.")
